# ImagetoImageTranslation
We present a conditional generative adversarial network to solve image-to-image translation problems. The generator utilizes the U-Net model - an encoder-decoder network with skips to shuttle low-level information between layers. We combine the pixel-wise reconstruction distance with the adversarial loss as the objective function to train the framework.We not only qualitatively but also quantitatively demonstrate the effectiveness of our model on synthesizing photos from labels, maps and reconstructing objects from edge maps.
